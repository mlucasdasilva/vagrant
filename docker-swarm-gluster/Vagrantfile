# -*- mode: ruby -*-
# vi: set ft=ruby :


$configurando_vm = <<-SCRIPT
sudo yum install epel-release -y
sudo yum install htop git vim sshpass -y
sudo curl -fsSL https://get.docker.com | bash
sudo usermod -aG docker vagrant
sudo systemctl enable docker
sudo systemctl start docker
sudo service firewalld stop
sudo systemctl disable firewalld
sudo yum install -y sshpass
sudo cp /etc/ssh/sshd_config /etc/ssh/sshd_config.bkp
sudo cp /vagrant/sshd_config /etc/ssh/sshd_config
sudo service sshd restart
setenforce 0
sudo cat /vagrant/hosts >> /etc/hosts
SCRIPT

$glusterfs = <<-SCRIPT
sudo yum install  -y wget centos-release-gluster  epel-release
sudo yum install  -y glusterfs-server
sudo systemctl stop firewalld
sudo systemctl disable firewalld
sudo systemctl start glusterd
sudo systemctl enable glusterd
sudo cp /etc/ssh/sshd_config /etc/ssh/sshd_config.bkp
sudo cp /vagrant/sshd_config /etc/ssh/sshd_config
sudo service sshd restart
setenforce 0
sudo cat /vagrant/hosts >> /etc/hosts
sudo mkdir -p /data/brick1/gv0
SCRIPT

$gluster_client = <<-SCRIPT
sudo yum install -y wget centos-release-gluster  epel-release
sudo yum install -y glusterfs glusterfs-fuse
sudo mkdir /mnt/gv0
sudo chattr +i /mnt/gv0 
sudo echo "gluster01:/gv0   /mnt/gv0  glusterfs backupvolfile-server=gluster02,defaults,_netdev,auto 0 0" >> /etc/fstab
sudo mount /mnt/gv0
SCRIPT


# All Vagrant configuration is done below. The "2" in Vagrant.configure
# configures the configuration version (we support older styles for
# backwards compatibility). Please don't change it unless you know what
# you're doing.

Vagrant.configure("2") do |config|
 
# config.vm.synced_folder ".", "/vagrant", automount: true , type: "smb"
# config.vm.network "forwarded_port", guest: 80, host: 8080


 config.vm.define "sd_gluster01" do |sd_gluster01|
  # Conf básica na VM
  sd_gluster01.vm.provider "virtualbox" do |v|
   v.name = "sd_gluster01"
   v.memory = 512
#   v.memory = 384
   v.cpus = 1
#   v.gui = true
  end
  # Conf básica no S.O
  sd_gluster01.vm.box = "centos/7"
  sd_gluster01.vm.hostname = "gluster01"
  sd_gluster01.vm.network "private_network", ip: "192.168.56.41"
  sd_gluster01.vm.network "private_network", ip: "192.168.50.41", virtualbox__intnet: "dcnet1"
  sd_gluster01.vm.network "forwarded_port", id: "ssh", guest: 22, host: 12221, auto_correct: true, protocol: "tcp"
  sd_gluster01.vm.provision "shell", inline: $glusterfs
 end

 config.vm.define "sd_gluster02" do |sd_gluster02|
  # Conf básica na VM
  sd_gluster02.vm.provider "virtualbox" do |v|
   v.name = "sd_gluster02"
   v.memory = 512
#   v.memory = 384
   v.cpus = 1
#   v.gui = true
  end
  # Conf básica no S.O
  sd_gluster02.vm.box = "centos/7"
  sd_gluster02.vm.hostname = "gluster02"
  sd_gluster02.vm.network "private_network", ip: "192.168.56.42"
  sd_gluster02.vm.network "private_network", ip: "192.168.50.42", virtualbox__intnet: "dcnet1"
  sd_gluster02.vm.network "forwarded_port", id: "ssh", guest: 22, host: 12222, auto_correct: true, protocol: "tcp"
  sd_gluster02.vm.provision "shell", inline: $glusterfs
 end

 config.vm.define "sd_gluster03" do |sd_gluster03|
  # Conf básica na VM
  sd_gluster03.vm.provider "virtualbox" do |v|
   v.name = "sd_gluster03"
   v.memory = 512
#   v.memory = 384
   v.cpus = 1
#   v.gui = true
  end
  # Conf básica no S.O
  sd_gluster03.vm.box = "centos/7"
  sd_gluster03.vm.hostname = "gluster03"
  sd_gluster03.vm.network "private_network", ip: "192.168.56.43"
  sd_gluster03.vm.network "private_network", ip: "192.168.50.43", virtualbox__intnet: "dcnet1"
  sd_gluster03.vm.network "forwarded_port", id: "ssh", guest: 22, host: 12223, auto_correct: true, protocol: "tcp"
  sd_gluster03.vm.provision "shell", inline: $glusterfs
  sd_gluster03.vm.provision "shell", inline: "sudo gluster peer probe gluster01"
  sd_gluster03.vm.provision "shell", inline: "sudo gluster peer probe gluster02"
  sd_gluster03.vm.provision "shell", inline: "sudo gluster volume create gv0 replica 3 gluster01:/data/brick1/gv0 gluster02:/data/brick1/gv0 gluster03:/data/brick1/gv0 force"
  sd_gluster03.vm.provision "shell", inline: "sudo gluster volume start gv0"
 end



 config.vm.define "sd_docker01", primary: true do |sd_docker01|
  # Conf básica na VM
  sd_docker01.vm.provider "virtualbox" do |v|
   v.name = "sd_docker01"
#   v.memory = 1024
   v.memory = 512
   v.cpus = 1
#   v.gui = true
  end
  sd_docker01.vm.box = "centos/7"
  sd_docker01.vm.hostname = "docker01"
  sd_docker01.vm.network "private_network", ip: "192.168.56.61"
  sd_docker01.vm.network "private_network", ip: "192.168.50.61", virtualbox__intnet: "dcnet1"
  sd_docker01.vm.network "forwarded_port", id: "ssh", guest: 22, host: 10221, auto_correct: true, protocol: "tcp"
  # Preparando a máquina para rodar o cluster swarm e instalando utilitários
  sd_docker01.vm.provision "shell", inline: $configurando_vm
  # Este trigger nao esta funcionando
  config.trigger.after :provision do |trigger|
    trigger.name = "join token"
    trigger.run = {inline: "vagrant ssh --no-tty -c 'sudo docker swarm join-token manager ^| grep token' sd_docker01 > join-mgr.sh"}
  end
  sd_docker01.vm.provision "shell", inline: "docker swarm init --advertise-addr 192.168.50.61"
  sd_docker01.vm.provision "shell", inline: "sudo docker swarm join-token manager | grep token > /home/vagrant/docker-join-mgr.sh"
  sd_docker01.vm.provision "shell", inline: $gluster_client
 end

 config.vm.define "sd_docker02" do |sd_docker02|
  # Conf básica na VM
  sd_docker02.vm.provider "virtualbox" do |v|
   v.name = "sd_docker02"
#   v.memory = 1024
   v.memory = 512
   v.cpus = 1
#   v.gui = true
  end
  # Conf básica no S.O
  sd_docker02.vm.box = "centos/7"
  sd_docker02.vm.hostname = "docker02"
  sd_docker02.vm.network "private_network", ip: "192.168.56.62"
  sd_docker02.vm.network "private_network", ip: "192.168.50.62", virtualbox__intnet: "dcnet1"
  sd_docker02.vm.network "forwarded_port", id: "ssh", guest: 22, host: 10222, auto_correct: true, protocol: "tcp"
  # Preparando a máquina para rodar o cluster swarm e instalando utilitários
  sd_docker02.vm.provision "shell", inline: $configurando_vm
  sd_docker02.vm.provision "shell", inline: "eval $( sshpass -p vagrant  ssh -oStrictHostKeyChecking=no docker01   docker swarm join-token manager | grep token )"
  sd_docker02.vm.provision "shell", inline: $gluster_client
 end

 config.vm.define "sd_docker03" do |sd_docker03|
  # Conf básica na VM
  sd_docker03.vm.provider "virtualbox" do |v|
   v.name = "sd_docker03"
#   v.memory = 1024
   v.memory = 512
   v.cpus = 1
#   v.gui = true
  end
  # Conf básica no S.O
  sd_docker03.vm.box = "centos/7"
  sd_docker03.vm.hostname = "docker03"
  sd_docker03.vm.network "private_network", ip: "192.168.56.63"
  sd_docker03.vm.network "private_network", ip: "192.168.50.63", virtualbox__intnet: "dcnet1"
  sd_docker03.vm.network "forwarded_port", id: "ssh", guest: 22, host: 10223, auto_correct: true, protocol: "tcp"
  # Preparando a máquina para rodar o cluster swarm e instalando utilitários
  sd_docker03.vm.provision "shell", inline: $configurando_vm
  sd_docker03.vm.provision "shell", inline: "eval $( sshpass -p vagrant  ssh -oStrictHostKeyChecking=no docker01   docker swarm join-token manager | grep token )"
  sd_docker03.vm.provision "shell", inline: $gluster_client
 end

 config.vm.define "sd_docker04" do |sd_docker04|
  # Conf básica na VM
  sd_docker04.vm.provider "virtualbox" do |v|
   v.name = "sd_docker04"
#   v.memory = 1024
   v.memory = 512
   v.cpus = 1
#   v.gui = true
  end
  # Conf básica no S.O
  sd_docker04.vm.box = "centos/7"
  sd_docker04.vm.hostname = "docker04"
  sd_docker04.vm.network "private_network", ip: "192.168.56.64"
  sd_docker04.vm.network "private_network", ip: "192.168.50.64", virtualbox__intnet: "dcnet1"
  sd_docker04.vm.network "forwarded_port", id: "ssh", guest: 22, host: 10224, auto_correct: true, protocol: "tcp"
  # Preparando a máquina para rodar o cluster swarm e instalando utilitários
  sd_docker04.vm.provision "shell", inline: $configurando_vm
  sd_docker04.vm.provision "shell", inline: "eval $( sshpass -p vagrant  ssh -oStrictHostKeyChecking=no docker01   docker swarm join-token worker | grep token )"
  sd_docker04.vm.provision "shell", inline: $gluster_client
 end


  # The most common configuration options are documented and commented below.
  # For a complete reference, please see the online documentation at
  # https://docs.vagrantup.com.

  # Every Vagrant development environment requires a box. You can search for
  # boxes at https://vagrantcloud.com/search.
##  config.vm.box = "base"

  # Disable automatic box update checking. If you disable this, then
  # boxes will only be checked for updates when the user runs
  # `vagrant box outdated`. This is not recommended.
  # config.vm.box_check_update = false

  # Create a forwarded port mapping which allows access to a specific port
  # within the machine from a port on the host machine. In the example below,
  # accessing "localhost:8080" will access port 80 on the guest machine.
  # NOTE: This will enable public access to the opened port
  # config.vm.network "forwarded_port", guest: 80, host: 8080

  # Create a forwarded port mapping which allows access to a specific port
  # within the machine from a port on the host machine and only allow access
  # via 127.0.0.1 to disable public access
  # config.vm.network "forwarded_port", guest: 80, host: 8080, host_ip: "127.0.0.1"

  # Create a private network, which allows host-only access to the machine
  # using a specific IP.
  # config.vm.network "private_network", ip: "192.168.33.10"

  # Create a public network, which generally matched to bridged network.
  # Bridged networks make the machine appear as another physical device on
  # your network.
  # config.vm.network "public_network"

  # Share an additional folder to the guest VM. The first argument is
  # the path on the host to the actual folder. The second argument is
  # the path on the guest to mount the folder. And the optional third
  # argument is a set of non-required options.
  # config.vm.synced_folder "../data", "/vagrant_data"

  # Provider-specific configuration so you can fine-tune various
  # backing providers for Vagrant. These expose provider-specific options.
  # Example for VirtualBox:
  #
  # config.vm.provider "virtualbox" do |vb|
  #   # Display the VirtualBox GUI when booting the machine
  #   vb.gui = true
  #
  #   # Customize the amount of memory on the VM:
  #   vb.memory = "1024"
  # end
  #
  # View the documentation for the provider you are using for more
  # information on available options.

  # Enable provisioning with a shell script. Additional provisioners such as
  # Ansible, Chef, Docker, Puppet and Salt are also available. Please see the
  # documentation for more information about their specific syntax and use.
  # config.vm.provision "shell", inline: <<-SHELL
  #   apt-get update
  #   apt-get install -y apache2
  # SHELL
 
end
